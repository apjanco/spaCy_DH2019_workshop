{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Rule-based Matcher Explorer](https://explosion.ai/demos/matcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ntpath\n",
    "import requests\n",
    "from os import path, makedirs, listdir\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from lxml import etree\n",
    "import standoffconverter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"1600\"\n",
       "            src=\"https://explosion.ai/demos/matcher\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x110f83ad0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame('https://explosion.ai/demos/matcher', width=1000, height=1600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15578876784678163569 HelloWorld 0 3 Hello, world\n"
     ]
    }
   ],
   "source": [
    "#https://spacy.io/usage/rule-based-matching#matcher\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Add match ID \"HelloWorld\" with no callback and one pattern\n",
    "pattern = [{\"LOWER\": \"hello\"}, {\"IS_PUNCT\": True}, {\"LOWER\": \"world\"}]\n",
    "matcher.add(\"HelloWorld\", None, pattern)\n",
    "\n",
    "doc = nlp(u\"Hello, world! Hello world!\")\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "    span = doc[start:end]  # The matched span\n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(123) 456-789'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://realpython.com/natural-language-processing-spacy-python/\n",
    "\n",
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "conference_org_text = ('There is a developer conference'\n",
    "    'happening on 21 July 2019 in London. It is titled'\n",
    "    ' \"Applications of Natural Language Processing\".'\n",
    "    ' There is a helpline number available'\n",
    "    ' at (123) 456-789')\n",
    "\n",
    "def extract_phone_number(nlp_doc):\n",
    "    pattern = [{'ORTH': '('}, {'SHAPE': 'ddd'},\n",
    "               {'ORTH': ')'}, {'SHAPE': 'ddd'},\n",
    "               {'ORTH': '-', 'OP': '?'},\n",
    "               {'SHAPE': 'ddd'}]\n",
    "    matcher.add('PHONE_NUMBER', None, pattern)\n",
    "    matches = matcher(nlp_doc)\n",
    "    for match_id, start, end in matches:\n",
    "        span = nlp_doc[start:end]\n",
    "        return span.text\n",
    "\n",
    "conference_org_doc = nlp(conference_org_text)\n",
    "extract_phone_number(conference_org_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phrase Matcher for stage directions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, download Shakespeare plays that have annotations for stage directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c9c66eb8256450dae5d073ca90ba45f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='downloading shakespeare edition', max=36, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d19bcae9ccbe48eb9f901422b28c1a3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='extracting xml', max=36, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cache_dir = \"downloads\"\n",
    "\n",
    "\n",
    "def get_urllist():\n",
    "    return pd.DataFrame([\n",
    "        {\"play_id\": \"jn\", \"url\": \"http://firstfolio.bodleian.ox.ac.uk/download/xml/F-jn.xml\"},\n",
    "        {\"play_id\": \"r2\", \"url\": \"http://firstfolio.bodleian.ox.ac.uk/download/xml/F-r2.xml\"},\n",
    "        {\"play_id\": \"1h4\", \"url\": \"http://firstfolio.bodleian.ox.ac.uk/download/xml/F-1h4.xml\"},\n",
    "        {\"play_id\": \"2h4\", \"url\": \"http://firstfolio.bodleian.ox.ac.uk/download/xml/F-2h4.xml\"},\n",
    "        {\"play_id\": \"h5\", \"url\": \"http://firstfolio.bodleian.ox.ac.uk/download/xml/F-h5.xml\"},\n",
    "        {\"play_id\": \"1h6\", \"url\": \"http://firstfolio.bodleian.ox.ac.uk/download/xml/F-1h6.xml\"},\n",
    "        {\"play_id\": \"2h6\", \"url\": \"http://firstfolio.bodleian.ox.ac.uk/download/xml/F-2h6.xml\"},\n",
    "        {\"play_id\": \"3h6\", \"url\": \"http://firstfolio.bodleian.ox.ac.uk/download/xml/F-3h6.xml\"},\n",
    "        {\"play_id\": \"r3\", \"url\": \"http://firstfolio.bodleian.ox.ac.uk/download/xml/F-r3.xml\"},\n",
    "        {\"play_id\": \"h8\", \"url\": \"http://firstfolio.bodleian.ox.ac.uk/download/xml/F-h8.xml\"},\n",
    "        {\"play_id\": \"rom\", \"url\": \"http://firstfolio.bodleian.ox.ac.uk/download/xml/F-rom.xml\"},\n",
    "        {\"play_id\": \"mnd\", \"url\": \"http://firstfolio.bodleian.ox.ac.uk/download/xml/F-mnd.xml\"},\n",
    "        {\"play_id\": \"jc\", \"url\": \"http://firstfolio.bodleian.ox.ac.uk/download/xml/F-jc.xml\"},\n",
    "        {\"play_id\": \"tn\", \"url\": \"http://firstfolio.bodleian.ox.ac.uk/download/xml/F-tn.xml\"},\n",
    "        {\"play_id\": \"tem\", \"url\": \"http://firstfolio.bodleian.ox.ac.uk/download/xml/F-tem.xml\"},\n",
    "        {\"play_id\": \"ham\", \"url\": \"http://firstfolio.bodleian.ox.ac.uk/download/xml/F-ham.xml\"},\n",
    "        {\"play_id\": \"mv\", \"url\": \"http://firstfolio.bodleian.ox.ac.uk/download/xml/F-mv.xml\"},\n",
    "        {\"play_id\": \"ayl\", \"url\": \"http://firstfolio.bodleian.ox.ac.uk/download/xml/F-ayl.xml\"},\n",
    "        {\"play_id\": \"shr\", \"url\": \"http://firstfolio.bodleian.ox.ac.uk/download/xml/F-shr.xml\"},\n",
    "        {\"play_id\": \"ado\", \"url\": \"http://firstfolio.bodleian.ox.ac.uk/download/xml/F-ado.xml\"},\n",
    "        {\"play_id\": \"lll\", \"url\": \"http://firstfolio.bodleian.ox.ac.uk/download/xml/F-lll.xml\"},\n",
    "        {\"play_id\": \"cor\", \"url\": \"http://firstfolio.bodleian.ox.ac.uk/download/xml/F-cor.xml\"},\n",
    "        {\"play_id\": \"err\", \"url\": \"http://firstfolio.bodleian.ox.ac.uk/download/xml/F-err.xml\"},\n",
    "        {\"play_id\": \"tgv\", \"url\": \"http://firstfolio.bodleian.ox.ac.uk/download/xml/F-tgv.xml\"},\n",
    "        {\"play_id\": \"wiv\", \"url\": \"http://firstfolio.bodleian.ox.ac.uk/download/xml/F-wiv.xml\"},\n",
    "        {\"play_id\": \"wt\", \"url\": \"http://firstfolio.bodleian.ox.ac.uk/download/xml/F-wt.xml\"},\n",
    "        {\"play_id\": \"tit\", \"url\": \"http://firstfolio.bodleian.ox.ac.uk/download/xml/F-tit.xml\"},\n",
    "        {\"play_id\": \"ant\", \"url\": \"http://firstfolio.bodleian.ox.ac.uk/download/xml/F-ant.xml\"},\n",
    "        {\"play_id\": \"mm\", \"url\": \"http://firstfolio.bodleian.ox.ac.uk/download/xml/F-mm.xml\"},\n",
    "        {\"play_id\": \"tim\", \"url\": \"http://firstfolio.bodleian.ox.ac.uk/download/xml/F-tim.xml\"},\n",
    "        {\"play_id\": \"lr\", \"url\": \"http://firstfolio.bodleian.ox.ac.uk/download/xml/F-lr.xml\"},\n",
    "        {\"play_id\": \"tro\", \"url\": \"http://firstfolio.bodleian.ox.ac.uk/download/xml/F-tro.xml\"},\n",
    "        {\"play_id\": \"aww\", \"url\": \"http://firstfolio.bodleian.ox.ac.uk/download/xml/F-aww.xml\"},\n",
    "        {\"play_id\": \"oth\", \"url\": \"http://firstfolio.bodleian.ox.ac.uk/download/xml/F-oth.xml\"},\n",
    "        {\"play_id\": \"mac\", \"url\": \"http://firstfolio.bodleian.ox.ac.uk/download/xml/F-mac.xml\"},\n",
    "        {\"play_id\": \"cym\", \"url\": \"http://firstfolio.bodleian.ox.ac.uk/download/xml/F-cym.xml\"},\n",
    "    ])\n",
    "\n",
    "def download(url, location, filename):\n",
    "\n",
    "    if not path.exists(location):\n",
    "        makedirs(location)\n",
    "    r = requests.get(url)\n",
    "    with open(path.join(location, filename+ \".xml\"), \"wb\") as fout:\n",
    "        fout.write(r.content)\n",
    "\n",
    "\n",
    "index = get_urllist()\n",
    "\n",
    "for _,row in tqdm(index.iterrows(), total=len(index), desc=\"downloading shakespeare edition\"):\n",
    "    download(row.url, cache_dir, row.play_id)\n",
    "\n",
    "standoffs = []\n",
    "\n",
    "for fn in tqdm([fn for fn in listdir(cache_dir) if fn[-4:]==\".xml\"], desc=\"extracting xml\"):\n",
    "    \n",
    "    tree = etree.fromstring(open(path.join(cache_dir, fn), \"rb\").read())\n",
    "    \n",
    "    so = standoffconverter.Standoff()\n",
    "    so.from_lxml_tree(tree)\n",
    "    \n",
    "    standoffs.append(so)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    \\n        \\n            \\n                The Life of Tymon of Athens from Mr. William Shakespeare'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(standoffs, random_state=4123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_true_stage_directions(standoffs):\n",
    "    stage_directions = []\n",
    "    indices = []\n",
    "    for standoff in standoffs:\n",
    "        indices.append([])\n",
    "        for annotation in standoff.standoffs:\n",
    "            if annotation[\"tag\"] == \"{http://www.tei-c.org/ns/1.0}stage\":\n",
    "                stage_directions.append(standoff.plain[annotation[\"begin\"]:annotation[\"end\"]])\n",
    "                indices[-1].append((annotation[\"begin\"],annotation[\"end\"]))\n",
    "    return stage_directions, indices\n",
    "                \n",
    "train_sd,_ = extract_true_stage_directions(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating some example matchers and validate\n",
    "The validation function also shows you examples of fales matches (false negatives and false positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "pattern = [{'LOWER': 'exit'},\n",
    "           {'IS_PUNCT': True}]\n",
    "matcher.add('EXIT', None, pattern)\n",
    "\n",
    "pattern = [{'LOWER': 'enter'},\n",
    "           {'IS_PUNCT': False}]\n",
    "matcher.add('Enter', None, pattern)\n",
    "\n",
    "\n",
    "def validate_stage_directions(matcher, data):\n",
    "\n",
    "    docs = [nlp(doc.plain) for doc in data]\n",
    "    \n",
    "    data_sd, data_indices = extract_true_stage_directions(data)\n",
    "    \n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    \n",
    "    fn_examples = []\n",
    "    fp_examples = []\n",
    "    \n",
    "    for idoc, doc in tqdm(enumerate(docs), total=len(docs)):\n",
    "        \n",
    "        ground_truth = np.zeros(len(doc.text)).astype(bool)\n",
    "        prediction = np.zeros(len(doc.text)).astype(bool)\n",
    "        for begin, end in data_indices[idoc]:\n",
    "            ground_truth[begin:end] = True\n",
    "            \n",
    "            \n",
    "        matches = matcher(doc)\n",
    "        for match_id, begin, end in matches:\n",
    "            prediction[doc[begin].idx:doc[end].idx + len(doc[end])-1] = True\n",
    "            if ground_truth[doc[begin].idx:doc[end].idx + len(doc[end])-1].sum() == 0:\n",
    "                fp_examples.append(doc[begin:end].text)\n",
    "                \n",
    "        \n",
    "        for begin, end in data_indices[idoc]:\n",
    "            if prediction[begin:end].sum() == 0:\n",
    "                fn_examples.append(doc.text[begin:end])\n",
    "\n",
    "        tp += np.logical_and(ground_truth, prediction).sum()\n",
    "        fn += np.logical_and(ground_truth, ~prediction).sum()\n",
    "        fp += np.logical_and(~ground_truth, prediction).sum()\n",
    "        tn += np.logical_and(~ground_truth, ~prediction).sum()\n",
    "\n",
    "    precision = tp /(tp + fp) if fp > 0 or tp > 0 else 0\n",
    "    recall = tp /(tp + fn) if tp > 0 or fn > 0 else 0\n",
    "    f1_score = 2*tp / (2*tp + fp + fn) if tp > 0 or fp > 0 or fn > 0 else 0\n",
    "    print(\"precision: {:.2f}, recall: {:.2f}, f1 {:.2f}\".format(precision, recall, f1_score))\n",
    "    \n",
    "    \n",
    "    print(\"## What has not been identified? For example:\")\n",
    "    print(\"\\n\".join(np.random.choice(fn_examples, 3)))\n",
    "    \n",
    "    print(\"\\n## What been identified. although it is not a stage direection? For example:\")\n",
    "    print(\"\\n\".join(np.random.choice(fp_examples, 3)))\n",
    "    \n",
    "    \n",
    "validate_stage_directions(matcher, train[:2])  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wh2",
   "language": "python",
   "name": "wh2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
