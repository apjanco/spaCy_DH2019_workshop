{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Rule-based Matcher Explorer](https://explosion.ai/demos/matcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from os import path, makedirs, listdir\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from lxml import etree\n",
    "import standoffconverter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import bodleian_downloader\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"1600\"\n",
       "            src=\"https://explosion.ai/demos/matcher\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x12ed269d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame('https://explosion.ai/demos/matcher', width=1000, height=1600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15578876784678163569 HelloWorld 0 3 Hello, world\n"
     ]
    }
   ],
   "source": [
    "#https://spacy.io/usage/rule-based-matching#matcher\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Add match ID \"HelloWorld\" with no callback and one pattern\n",
    "pattern = [{\"LOWER\": \"hello\"}, {\"IS_PUNCT\": True}, {\"LOWER\": \"world\"}]\n",
    "matcher.add(\"HelloWorld\", None, pattern)\n",
    "\n",
    "doc = nlp(u\"Hello, world! Hello world!\")\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "    span = doc[start:end]  # The matched span\n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(123) 456-789'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://realpython.com/natural-language-processing-spacy-python/\n",
    "\n",
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "conference_org_text = ('There is a developer conference'\n",
    "    'happening on 21 July 2019 in London. It is titled'\n",
    "    ' \"Applications of Natural Language Processing\".'\n",
    "    ' There is a helpline number available'\n",
    "    ' at (123) 456-789')\n",
    "\n",
    "def extract_phone_number(nlp_doc):\n",
    "    pattern = [{'ORTH': '('}, {'SHAPE': 'ddd'},\n",
    "               {'ORTH': ')'}, {'SHAPE': 'ddd'},\n",
    "               {'ORTH': '-', 'OP': '?'},\n",
    "               {'SHAPE': 'ddd'}]\n",
    "    matcher.add('PHONE_NUMBER', None, pattern)\n",
    "    matches = matcher(nlp_doc)\n",
    "    for match_id, start, end in matches:\n",
    "        span = nlp_doc[start:end]\n",
    "        return span.text\n",
    "\n",
    "conference_org_doc = nlp(conference_org_text)\n",
    "extract_phone_number(conference_org_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phrase Matcher for stage directions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, download Shakespeare plays that have annotations for stage directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0d0edb3fb17470398a9f0f590b4563f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='download and extract xml', max=1, style=Proâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "standoffs = []\n",
    "\n",
    "for fn in tqdm(bodleian_downloader.get_file_descriptors(), desc=\"download and extract xml\"):\n",
    "\n",
    "    tree = etree.fromstring(open(fn, \"rb\").read())\n",
    "\n",
    "    so = standoffconverter.Standoff()\n",
    "    so.from_lxml_tree(tree)\n",
    "\n",
    "    standoffs.append(so)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(standoffs, random_state=4123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_true_stage_directions(standoffs):\n",
    "    stage_directions = []\n",
    "    indices = []\n",
    "    for standoff in standoffs:\n",
    "        indices.append([])\n",
    "        for annotation in standoff.standoffs:\n",
    "            if annotation[\"tag\"] == \"{http://www.tei-c.org/ns/1.0}stage\":\n",
    "                stage_directions.append(standoff.plain[annotation[\"begin\"]:annotation[\"end\"]])\n",
    "                indices[-1].append((annotation[\"begin\"],annotation[\"end\"]))\n",
    "    return stage_directions, indices\n",
    "                \n",
    "train_sd,_ = extract_true_stage_directions(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating some example matchers and validate\n",
    "The validation function also shows you examples of fales matches (false negatives and false positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bce69394611c45a1a7f426db46288966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-41-08d2e578daf1>(61)validate_stage_directions()\n",
      "-> print(doc[begin:end])\n",
      "(Pdb) gt\n",
      "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False])\n",
      "(Pdb) len(doc[end])\n",
      "41\n",
      "(Pdb) doc[end]\n",
      "\n",
      "                  \n",
      "                     \n",
      "(Pdb) len(doc[end].text)\n",
      "41\n",
      "(Pdb) q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-08d2e578daf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m \u001b[0mvalidate_stage_directions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatcher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-08d2e578daf1>\u001b[0m in \u001b[0;36mvalidate_stage_directions\u001b[0;34m(matcher, data)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m                 fp_examples.append({\n\u001b[1;32m     63\u001b[0m                     \u001b[0;34m\"phrase\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-08d2e578daf1>\u001b[0m in \u001b[0;36mvalidate_stage_directions\u001b[0;34m(matcher, data)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m                 fp_examples.append({\n\u001b[1;32m     63\u001b[0m                     \u001b[0;34m\"phrase\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.4/Frameworks/Python.framework/Versions/3.7/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.4/Frameworks/Python.framework/Versions/3.7/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "\n",
    "pattern = [{'ORTH': 'Enter'},\n",
    "           {'IS_PUNCT': True}]\n",
    "\n",
    "matcher.add('ENTER', None, pattern)\n",
    "\n",
    "\n",
    "pattern = [{'ORTH': 'Enter'},\n",
    "           {'POS': 'PROPN'},\n",
    "           {'IS_PUNCT': True}]\n",
    "\n",
    "matcher.add('ENTER_SOMEONE', None, pattern)\n",
    "\n",
    "pattern = [{'ORTH': 'Exit'},\n",
    "           {'IS_PUNCT': True}]\n",
    "\n",
    "matcher.add('EXIT', None, pattern)\n",
    "\n",
    "pattern = [{'ORTH': 'Exit'},\n",
    "           {'POS': 'PROPN'},\n",
    "           {'IS_PUNCT': True}]\n",
    "\n",
    "matcher.add('EXIT_SOMEONE', None, pattern)\n",
    "\n",
    "\n",
    "def validate_stage_directions(matcher, data):\n",
    "\n",
    "    docs = [nlp(doc.plain) for doc in data]\n",
    "    \n",
    "    data_sd, data_indices = extract_true_stage_directions(data)\n",
    "    \n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    \n",
    "    fn_examples = []\n",
    "    fp_examples = []\n",
    "    \n",
    "    tp_match_names = []\n",
    "    fp_match_names = []\n",
    "    \n",
    "    \n",
    "    for idoc, doc in tqdm(enumerate(docs), total=len(docs)):\n",
    "        \n",
    "        ground_truth = np.zeros(len(doc.text)).astype(bool)\n",
    "        prediction = np.zeros(len(doc.text)).astype(bool)\n",
    "        for begin, end in data_indices[idoc]:\n",
    "            ground_truth[begin:end] = True\n",
    "            \n",
    "        \n",
    "        matches = matcher(doc)\n",
    "        for match_id, begin, end in matches:\n",
    "            prediction[doc[begin].idx:doc[end].idx + len(doc[end])] = True\n",
    "            gt = ground_truth[doc[begin].idx:doc[end].idx + len(doc[end])]\n",
    "            if gt.sum() < len(gt):\n",
    "                fp_examples.append({\n",
    "                    \"phrase\": doc[begin:end].text,\n",
    "                    \"phrase_with_context\":doc[max(0, begin-5):min(len(doc),end+5)].text\n",
    "                })\n",
    "                fp_match_names.append(\n",
    "                    nlp.vocab.strings[match_id]\n",
    "                )\n",
    "            else:\n",
    "                tp_match_names.append(\n",
    "                    nlp.vocab.strings[match_id]\n",
    "                )\n",
    "        \n",
    "        for begin, end in data_indices[idoc]:\n",
    "            if prediction[begin:end].sum() < len(prediction[begin:end]):\n",
    "                fn_examples.append({\n",
    "                    \"phrase\": doc.text[begin:end],\n",
    "                    \"phrase_with_context\":doc.text[max(0,begin-25):min(len(doc.text), end + 25)]\n",
    "                })\n",
    "\n",
    "        tp += np.logical_and(ground_truth, prediction).sum()\n",
    "        fn += np.logical_and(ground_truth, ~prediction).sum()\n",
    "        fp += np.logical_and(~ground_truth, prediction).sum()\n",
    "        tn += np.logical_and(~ground_truth, ~prediction).sum()\n",
    "\n",
    "    precision = tp /(tp + fp) if fp > 0 or tp > 0 else 0\n",
    "    recall = tp /(tp + fn) if tp > 0 or fn > 0 else 0\n",
    "    f1_score = 2*tp / (2*tp + fp + fn) if tp > 0 or fp > 0 or fn > 0 else 0\n",
    "    print(\"precision: {:.2f}, recall: {:.2f}, f1 {:.2f}\".format(precision, recall, f1_score))\n",
    "    \n",
    "    \n",
    "    printmd(\"**What has not been identified? For example:**\")\n",
    "    for ex_dict in np.random.choice(fn_examples, 3):\n",
    "        for k,v in ex_dict.items():\n",
    "            printmd(\"*\" + k + \"*\")\n",
    "            print(\">\", v)\n",
    "    \n",
    "    printmd(\"\\n **What has been identified. although it is not a stage direction? For example:**\")\n",
    "    for ex_dict in np.random.choice(fp_examples, 3):\n",
    "        for k,v in ex_dict.items():\n",
    "            printmd(\"*\" + k + \"*\")\n",
    "            print(\">\", v)\n",
    "            \n",
    "\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,6))\n",
    "    fig.suptitle('how often did a pattern apply?')\n",
    "    \n",
    "    keys, counts = np.unique(tp_match_names, return_counts=True)\n",
    "    ax1.bar(keys,counts)\n",
    "    ax1.set_title(\"correctly applied pattern\")\n",
    "    \n",
    "    keys, counts = np.unique(fp_match_names, return_counts=True)\n",
    "    ax2.bar(keys, counts)\n",
    "    ax2.set_title(\"incorrectly applied pattern\")\n",
    "    \n",
    "    \n",
    "validate_stage_directions(matcher, train[:2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wh2",
   "language": "python",
   "name": "wh2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
