{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ✨Prodigy \n",
    "\n",
    "[Prodigy Documentation](https://spacy.apjan.co/docs/)\n",
    "\n",
    "Exercise I: Basic NER with pre-trained spaCy models [source](https://towardsdatascience.com/named-entity-recognition-with-nltk-and-spacy-8c4a7d88e7da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pickle\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "\n",
    "nlp = en_core_web_sm.load()\n",
    "spec = {\"tei\":\"http://www.tei-c.org/ns/1.0\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Hosted by \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Utrecht University\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", the \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    2019\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " iteration of the Digital Humanities (DH) conference, the annual international conference of \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    the Alliance of Digital Humanities Organizations\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", will take place in the medieval city of \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Utrecht\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    one\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " of the oldest cities in the \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Netherlands\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ". The city’s rapid modernization and growth has inspired the conference’s guiding theme, complexity.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(\n",
    "    \"Hosted by Utrecht University, the 2019 iteration of the Digital Humanities (DH) conference, the annual international conference of the Alliance of Digital Humanities Organizations, will take place in the medieval city of Utrecht, one of the oldest cities in the Netherlands. The city’s rapid modernization and growth has inspired the conference’s guiding theme, complexity.\"\n",
    ")\n",
    "displacy.render(doc, style=\"ent\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "This works very well for many 20th and 21st century texts.  But what about 17th century English?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">ITEM because that the kings most deare \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Uncle\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", the king of \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Denmarke\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Norway &amp; Sweveland\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", as the same our soveraigne Lord the king of his intimation hath understood, considering the manifold &amp; great losses, perils, hurts and damage which have late happened aswell to him and his, as to other foraines and strangers, and also friends and speciall subjects of our said soveraigne Lord the king of his \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Realme of England\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", by ye going in, entring &amp; passage of such forain &amp; strange persons into his realme of \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Norwey &amp;\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " other dominions, streits, territories, jurisdictions &amp; places subdued and subject to him, specially into his \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Iles of Fynmarke\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", and elswhere, aswell in their persons as their things and goods</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(\n",
    "    \"ITEM because that the kings most deare Uncle, the king of Denmarke, Norway & Sweveland, as the same our soveraigne Lord the king of his intimation hath understood, considering the manifold & great losses, perils, hurts and damage which have late happened aswell to him and his, as to other foraines and strangers, and also friends and speciall subjects of our said soveraigne Lord the king of his Realme of England, by ye going in, entring & passage of such forain & strange persons into his realme of Norwey & other dominions, streits, territories, jurisdictions & places subdued and subject to him, specially into his Iles of Fynmarke, and elswhere, aswell in their persons as their things and goods\"\n",
    ")\n",
    "displacy.render(doc, style=\"ent\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to ✨Prodigy\n",
    "\n",
    "Prodigy is an annotation tool for active machine teaching.  Prodigy makes it possible to quickly experiment and improve models with relatively little data, time and typically only one annotator.  Prodigy will sort a model's results by certainty, and ask for human input where the results are most ambiguous. Prodigy stores these annotations and uses them to update the model.  Machine teaching can be used to: \n",
    "\n",
    "- improve an existing model for a specific context or set of documents\n",
    "- add a new entity or category to a text model \n",
    "- custom image categorization and object recognition\n",
    "\n",
    "Prodigy does require a license to use. Researchers at degree-granting academic institutions can request a free research license [here](https://prodi.gy/forms/research-license)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, our goal is to teach an existing English-language model to identify 17th century place names.\n",
    "\n",
    "There are several approaches that we could take to this problem.  Different approaches can lend better or worse result and experimentation is an essential part of any machine learning project. \n",
    "\n",
    "## How can we teach a statistical language model that Sweveland is a place?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Manual annotation**\n",
    "\n",
    "Some researchers may prefer to add seed annotations manually.  Using Prodigy, you can add seed terms by hand.   \n",
    "`prodigy ner.manual historic_places en_core_web_sm principal_navigations.txt --label PLACE`\n",
    "For certain personalities, myself included, this is actually kind of fun and a good way to think about the text and the goals of your experiment.   \n",
    "\n",
    "For the current problem, this is not my suggested method.  Place names are very distinct and hard to identify from context.  If the model knew that York is a place, how could it learn that New York is also a place? By contrast, titles typically occur before proper names.  It could learn that both Professor and Doctor are titles without knowing that those specific terms are used as titles.  In our current case, it's best to give the model as many examples of place names as possible.  Note that with spaCy, we are working with place names as [patterns](https://spacy.apjan.co/docs/#match-patterns) so the model can learn that place names often have several parts.  \n",
    "\n",
    "**Seed term patterns** \n",
    "\n",
    "We're going to give the model as many examples of historic places names as we can to get the learning process started. To do this, I have chosen to mine a text that has already been markedup in TEI with 17th century place names and is available from the Perseus Project.  We're going to use Richard Hakluyt's [*The Principal Navigations, Voyages, Traffiques, and Discoveries of the English Nation* (1599)](http://www.perseus.tufts.edu/hopper/text?doc=Perseus%3Atext%3A1999.03.0070%3Anarrative%3D1).  I have chosen an English-language example because we'll be annotating the text in this workshop and English is a working language for DH2019.  However, you can work with texts in [any language](https://spacy.io/usage/adding-languages) even those that do not have an existing spaCy language model ([colonial Zapotec](https://ticha.haverford.edu/) for example!).    \n",
    "\n",
    "\n",
    "\n",
    "**New category or existing?** \n",
    "\n",
    "We will need to choose whether we want to add a new entity to the model (let's call it \"PLACE\") or improve the existing \"GPE\" entity for our historic places.  Either one works.  If we improve an existing entity, we retain the existing training and examples. A new entity makes it easier to distinguish between what we have taught the model and previous training.  This can also address potential bias in previous training data.  For that reason, we'll add \"PLACE\" as a new category.     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the TEI files from Persius \n",
    "- We're going to extract a list of all the place names from the text to create a patterns JSONL file.\n",
    "- We'll also extract the raw text to create a set of training documents. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to download the table of contents and create a list of the 937 segments of the document. We will then get each page, remove the place names (`<name type=\"place\">Utrect</name>`) and add them to a places list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickles loaded\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from lxml import etree\n",
    "\n",
    "def tei_loader(url):\n",
    "    tei = urlopen(url).read()\n",
    "    return etree.XML(tei)\n",
    "\n",
    "table_of_contents_url = \"http://www.perseus.tufts.edu/hopper/xmltoc?doc=Perseus%3Atext%3A1999.03.0070%3Anarrative%3D1\"\n",
    "table_of_contents_xml = tei_loader(table_of_contents_url)\n",
    "\n",
    "if not os.path.exists('refs.pickle'):\n",
    "    chunks = table_of_contents_xml.xpath(\"//chunk[@ref]\")\n",
    "    refs = [chunk.get('ref') for chunk in chunks] \n",
    "    # an example ref 'Perseus%3Atext%3A1999.03.0070%3Anarrative%3D6'\n",
    "\n",
    "\n",
    "    places = []\n",
    "\n",
    "    for ref in refs:\n",
    "\n",
    "        url = 'http://www.perseus.tufts.edu/hopper/xmlchunk?doc=' + ref\n",
    "        try:\n",
    "            tei = tei_loader(url)\n",
    "\n",
    "            #get all <name type='place'> tags\n",
    "            for place in tei.findall(\".//name[@type='place']\", namespaces=spec):\n",
    "                places.append(place.text.replace('\\n',''))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "    pickle.dump(places, open('places.pickle', 'wb'))\n",
    "    pickle.dump(refs, open('refs.pickle', 'wb'))\n",
    "\n",
    "else:\n",
    "    places = pickle.load(open('places.pickle', 'rb'))\n",
    "    refs = pickle.load(open('refs.pickle', 'rb'))\n",
    "    print('pickles loaded')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of documents:  937\n",
      "number of places found:  2279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'York'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('number of documents: ', len(refs))\n",
    "print('number of places found: ', len(set(places)))\n",
    "places[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a patterns.jsonl file with seed terms.  \n",
    "These terms provide examples that the model can use to learn the new category. It is good to use as many terms as are practical; preferably 100-200. Further examples of patterns files can be found [here](https://github.com/explosion/prodigy-recipes/tree/master/example-patterns) and there is a very helpful tool for creating patterns that are relevant to your projects and texts [here](https://explosion.ai/demos/matcher)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "new_label = 'PLACE'\n",
    "\n",
    "if not os.path.exists('patterns.jsonl'):\n",
    "    with open('patterns.jsonl','w') as f:\n",
    "        for place in set(places):   # A set is used here to remove duplicate place names\n",
    "            \n",
    "            row = {}\n",
    "                \n",
    "            row['label'] = new_label\n",
    "            row['pattern'] = []\n",
    "            for token in place.split():\n",
    "                pattern = {}\n",
    "                pattern['lower'] = token.lower()\n",
    "                row['pattern'].append(pattern)\n",
    "        \n",
    "            f.write(str(json.dumps(row) +'\\n')) \n",
    "            \n",
    "        '''Polite intervention:  \n",
    "        Sweveland is not in our list of historic and beautiful places, but is essential to the narrative of this notebook.\n",
    "        To correct this error, the line below has been added, with appologies to our colleagues from Sweveland'''\n",
    "        row = {\"label\": \"PLACE\", \"pattern\": [{\"lower\": \"sweveland\"}]}\n",
    "        f.write(json.dumps(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"label\": \"PLACE\", \"pattern\": [{\"lower\": \"wardhouse\"}]}\n",
      "{\"label\": \"PLACE\", \"pattern\": [{\"lower\": \"sea\"}, {\"lower\": \"southwest\"}]}\n",
      "{\"label\": \"PLACE\", \"pattern\": [{\"lower\": \"silauria\"}]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('patterns.jsonl','r') as f:\n",
    "    print(f.read()[:185])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file already exists. This process takes several minutes. To re-run, change process_anew to True. You can also adjust the percentage of the corpus to be gathered.\n"
     ]
    }
   ],
   "source": [
    "#Now to extract the full text\n",
    "percent_of_texts_to_process = 0.05 \n",
    "'''We are only using a tiny portion of the text for annotation.  \n",
    "Unlike many machine learning tasks, in this case, more text data for annotations does not necessarily\n",
    "improve learning. More text will dramatically increase Prodigy's memory usage, so keep that in mind.'''\n",
    "\n",
    "end_index = int(len(refs) * percent_of_texts_to_process)\n",
    "\n",
    "if os.path.exists(\"principal_navigations.txt\"):\n",
    "    print(\n",
    "        \"The file already exists. This process takes several minutes. To re-run, change process_anew to True. You can also adjust the percentage of the corpus to be gathered.\"\n",
    "    )\n",
    "    \n",
    "process_anew = False\n",
    "if process_anew:\n",
    "    txts = []\n",
    "    for ref in refs[:end_index]:\n",
    "\n",
    "        url = 'http://www.perseus.tufts.edu/hopper/xmlchunk?doc=' + ref\n",
    "        try:\n",
    "            tei = tei_loader(url)\n",
    "\n",
    "            new_txt = []\n",
    "            for body in tei.iter('body'):\n",
    "                new_txt.append(''.join(body.itertext()).strip().replace('\\n',''))\n",
    "                txts.append(''.join(new_txt))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "\n",
    "    full_text = [\n",
    "        txt.replace(\"        \", \" \").replace(\"   \", \" \").replace(\"  \", \" \")\n",
    "        for txt in txts\n",
    "    ]\n",
    "    \n",
    "    with open('principal_navigations.txt','w') as f:\n",
    "        f.write(str(full_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A branch of a Statute made in the eight yeere of Henry the sixt, for the trade to Norwey, Sweveland, Den marke, and Fynmarke. ITEM because that the kings most deare Uncle, the kingof Denmarke, Norway & Sweveland, as the same oursoveraigne Lord the king of his intimation hath understood, considering the manifold & great losses, perils,hurts and damage which have late happened aswell tohim and his, as to other foraines and strangers, and alsofriends and speciall subjects of our said soveraigne Lordthe king of his Realme of England, by ye going in,entring & passage of such forain & strange pers\n"
     ]
    }
   ],
   "source": [
    "with open('principal_navigations.txt','r') as f: \n",
    "    print(f.read()[:600])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With patterns and text files created, we can now work with ✨Prodigy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `dataset` command will create a database table to save your annotations. The default is sqlite, but you can connect to [MySQL or postgres](https://spacy.apjan.co/docs/#database-setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  ✨  Successfully added 'historic_places' to database SQLite.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!prodigy dataset historic_places \"A dataset for British historic places\" --author Andy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you'd like to delete a dataset:   \n",
    "\n",
    "`prodigy drop historic_places`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Plaintext to TEI. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start the annotation application for a named entity recognition task, we use the `ner.teach` recipe. Similar [built-in recipes](https://spacy.apjan.co/docs/#built-in-recipes) are available for: \n",
    "- text categorization (textcat.teach) \n",
    "- part of speech tagging (pos.teach)  \n",
    "- vectors & terminology (terms.teach)\n",
    "- computer vision (image.manual)\n",
    "\n",
    "In the command below, we use the `ner.teach` recipe to annotate the `historic_places` dataset, using the `en_core_web_sm` model to add the new entity `PLACE` after loading the patterns in `patterns.jsonl`.  \n",
    "\n",
    "**Please be patient, this next step can take a few minutes to load**  \n",
    "Click on the stop button to intterupt the kernel when you're done. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 labels: PLACE\n",
      "\n",
      "  ✨  Starting the web server at http://spacy.apjan.co:8080 ...\n",
      "  Open the app in your browser and start annotating!\n",
      "\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!prodigy ner.manual historic_places en_core_web_sm principal_navigations.txt --label PLACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 labels: PLACE\n",
      "\n",
      "  ✨  Starting the web server at http://spacy.apjan.co:8080 ...\n",
      "  Open the app in your browser and start annotating!\n",
      "\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!prodigy ner.teach historic_places en_core_web_sm principal_navigations.txt --label PLACE --patterns patterns.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have completed adding annotations, the next step is to train the model.  \n",
    "\n",
    "In the command below, we use `ner.batch-train` to use the annotations in the `historic_places` dataset to train the `en_core_web_sm` model on the new entity `PLACE`.  We then save the updated model as `new_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 labels: PLACE\n",
      "\n",
      "Loaded model en_core_web_sm\n",
      "Using 50% of accept/reject examples (14) for evaluation\n",
      "Using 100% of remaining examples (14) for training\n",
      "Dropout: 0.2  Batch size: 4  Iterations: 10  \n",
      "\n",
      "\n",
      "BEFORE      0.000            \n",
      "Correct     \u001b[38;5;77m0\u001b[0m  \n",
      "Incorrect   \u001b[38;5;197m19\u001b[0m\n",
      "Entities    58               \n",
      "Unknown     0                \n",
      "\n",
      "#            LOSS         RIGHT        WRONG        ENTS         SKIP         ACCURACY  \n",
      "01           739.134      0            19           14           0            0.000     \n",
      "02           698.114      2            17           130          0            0.105     \n",
      "03           597.772      2            17           96           0            0.105     \n",
      "04           614.653      1            18           62           0            0.053     \n",
      "05           543.914      2            17           45           0            0.105     \n",
      "06           619.696      1            18           29           0            0.053     \n",
      "07           585.380      4            15           37           0            0.211     \n",
      "08           555.982      4            15           36           0            0.211     \n",
      "09           495.572      4            15           33           0            0.211     \n",
      "10           502.489      4            15           34           0            0.211     \n",
      "\n",
      "Correct     \u001b[38;5;77m4\u001b[0m  \n",
      "Incorrect   \u001b[38;5;197m15\u001b[0m\n",
      "Baseline    0.000            \n",
      "Accuracy    0.211            \n",
      "\n",
      "\n",
      "Model: /home/ajanco/spaCy_DH2019_workshop/unit3/new_model\n",
      "Training data: /home/ajanco/spaCy_DH2019_workshop/unit3/new_model/training.jsonl\n",
      "Evaluation data: /home/ajanco/spaCy_DH2019_workshop/unit3/new_model/evaluation.jsonl\n"
     ]
    }
   ],
   "source": [
    "!prodigy ner.batch-train historic_places en_core_web_sm --label PLACE --output new_model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you think the model would benefit from more training you can run this process again to load and update `new_model`.  You can also add the `--n-iter` argument to specify the number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 labels: PLACE\n",
      "\n",
      "Loaded model new_model\n",
      "Using 50% of accept/reject examples (14) for evaluation\n",
      "Using 100% of remaining examples (14) for training\n",
      "Dropout: 0.2  Batch size: 4  Iterations: 120  \n",
      "\n",
      "\n",
      "BEFORE      0.632           \n",
      "Correct     \u001b[38;5;77m12\u001b[0m\n",
      "Incorrect   \u001b[38;5;197m7\u001b[0m\n",
      "Entities    20              \n",
      "Unknown     7               \n",
      "\n",
      "#            LOSS         RIGHT        WRONG        ENTS         SKIP         ACCURACY  \n",
      "01           13.781       12           7            25           0            0.632     \n",
      "02           13.590       12           7            29           0            0.632     \n",
      "03           43.161       12           7            28           0            0.632     \n",
      "04           7.324        12           7            26           0            0.632     \n",
      "05           33.595       12           7            22           0            0.632     \n",
      "06           15.679       12           7            22           0            0.632     \n",
      "07           37.153       12           7            19           0            0.632     \n",
      "08           26.773       10           9            18           0            0.526     \n",
      "09           18.952       10           9            17           0            0.526     \n",
      "10           20.559       10           9            17           0            0.526     \n",
      "11           10.653       10           9            16           0            0.526     \n",
      "12           10.449       10           9            16           0            0.526     \n",
      "13           30.797       10           9            16           0            0.526     \n",
      "14           24.592       10           9            18           0            0.526     \n",
      "15           15.316       10           9            18           0            0.526     \n",
      "16           17.433       11           8            19           0            0.579     \n",
      "17           31.112       12           7            24           0            0.632     \n",
      "18           31.081       12           7            25           0            0.632     \n",
      "19           13.760       12           7            25           0            0.632     \n",
      "20           6.999        12           7            25           0            0.632     \n",
      "21           15.186       11           8            21           0            0.579     \n",
      "22           16.156       11           8            20           0            0.579     \n",
      "23           18.615       11           8            20           0            0.579     \n",
      "24           35.273       11           8            18           0            0.579     \n",
      "25           18.965       11           8            17           0            0.579     \n",
      "26           19.765       11           8            18           0            0.579     \n",
      "27           20.966       11           8            18           0            0.579     \n",
      "28           16.299       11           8            18           0            0.579     \n",
      "29           31.497       11           8            18           0            0.579     \n",
      "30           57.582       11           8            18           0            0.579     \n",
      "31           23.988       11           8            18           0            0.579     \n",
      "32           13.565       11           8            18           0            0.579     \n",
      "33           7.164        11           8            17           0            0.579     \n",
      "34           9.019        11           8            18           0            0.579     \n",
      "35           24.177       11           8            18           0            0.579     \n",
      "36           6.578        11           8            18           0            0.579     \n",
      "37           13.454       11           8            18           0            0.579     \n",
      "38           40.353       11           8            18           0            0.579     \n",
      "39           30.966       11           8            18           0            0.579     \n",
      "40           48.473       11           8            18           0            0.579     \n",
      "41           15.994       11           8            18           0            0.579     \n",
      "42           36.478       11           8            19           0            0.579     \n",
      "43           20.263       11           8            19           0            0.579     \n",
      "44           15.458       11           8            20           0            0.579     \n",
      "45           25.910       11           8            20           0            0.579     \n",
      "46           10.556       11           8            20           0            0.579     \n",
      "47           14.075       11           8            20           0            0.579     \n",
      "48           19.205       11           8            19           0            0.579     \n",
      "49           12.767       11           8            19           0            0.579     \n",
      "50           17.231       11           8            19           0            0.579     \n",
      "51           42.496       11           8            18           0            0.579     \n",
      "52           19.426       11           8            18           0            0.579     \n",
      "53           12.619       11           8            18           0            0.579     \n",
      "54           35.398       11           8            17           0            0.579     \n",
      "55           25.786       11           8            17           0            0.579     \n",
      "56           31.956       11           8            18           0            0.579     \n",
      "57           36.208       11           8            18           0            0.579     \n",
      "58           21.977       11           8            18           0            0.579     \n",
      "59           26.619       11           8            18           0            0.579     \n",
      "60           23.696       11           8            18           0            0.579     \n",
      "61           20.527       11           8            17           0            0.579     \n",
      "62           33.435       11           8            17           0            0.579     \n",
      "63           24.290       11           8            17           0            0.579     \n",
      "64           6.928        11           8            17           0            0.579     \n",
      "65           25.669       11           8            18           0            0.579     \n",
      "66           15.644       11           8            19           0            0.579     \n",
      "67           14.918       11           8            19           0            0.579     \n",
      "68           4.558        11           8            19           0            0.579     \n",
      "69           29.637       11           8            20           0            0.579     \n",
      "70           17.785       11           8            21           0            0.579     \n",
      "71           24.464       11           8            21           0            0.579     \n",
      "72           31.352       11           8            21           0            0.579     \n",
      "73           16.280       11           8            21           0            0.579     \n",
      "74           22.421       11           8            21           0            0.579     \n",
      "75           16.494       11           8            21           0            0.579     \n",
      "76           25.417       11           8            21           0            0.579     \n",
      "77           15.983       11           8            21           0            0.579     \n",
      "78           17.988       11           8            20           0            0.579     \n",
      "79           9.291        11           8            20           0            0.579     \n",
      "80           15.630       11           8            20           0            0.579     \n",
      "81           27.613       11           8            20           0            0.579     \n",
      "82           15.820       11           8            20           0            0.579     \n",
      "83           13.476       11           8            20           0            0.579     \n",
      "84           28.605       11           8            20           0            0.579     \n",
      "85           22.564       11           8            20           0            0.579     \n",
      "86           10.897       11           8            21           0            0.579     \n",
      "87           37.093       11           8            21           0            0.579     \n",
      "88           9.081        11           8            21           0            0.579     \n",
      "89           18.891       11           8            21           0            0.579     \n",
      "90           23.922       11           8            21           0            0.579     \n",
      "91           22.972       11           8            21           0            0.579     \n",
      "92           37.347       11           8            21           0            0.579     \n",
      "93           26.832       11           8            21           0            0.579     \n",
      "94           5.956        11           8            20           0            0.579     \n",
      "95           18.749       11           8            20           0            0.579     \n",
      "96           14.942       11           8            21           0            0.579     \n",
      "97           13.576       11           8            21           0            0.579     \n",
      "98           15.607       11           8            22           0            0.579     \n",
      "99           14.917       11           8            22           0            0.579     \n",
      "100          23.042       11           8            22           0            0.579     \n",
      "101          24.919       11           8            22           0            0.579     \n",
      "102          3.047        11           8            20           0            0.579     \n",
      "103          19.216       11           8            20           0            0.579     \n",
      "104          24.256       11           8            20           0            0.579     \n",
      "105          22.886       11           8            20           0            0.579     \n",
      "106          7.152        11           8            20           0            0.579     \n",
      "107          6.254        11           8            20           0            0.579     \n",
      "108          6.025        11           8            20           0            0.579     \n",
      "109          1.205        11           8            20           0            0.579     \n",
      "110          42.179       11           8            20           0            0.579     \n",
      "111          8.289        11           8            20           0            0.579     \n",
      "112          23.455       11           8            20           0            0.579     \n",
      "113          27.471       11           8            20           0            0.579     \n",
      "114          31.478       11           8            20           0            0.579     \n",
      "115          7.608        11           8            20           0            0.579     \n",
      "116          36.968       11           8            20           0            0.579     \n",
      "117          12.770       11           8            20           0            0.579     \n",
      "118          22.114       11           8            20           0            0.579     \n",
      "119          11.475       11           8            20           0            0.579     \n",
      "120          22.160       11           8            20           0            0.579     \n",
      "\n",
      "Correct     \u001b[38;5;77m12\u001b[0m\n",
      "Incorrect   \u001b[38;5;197m7\u001b[0m\n",
      "Baseline    0.632           \n",
      "Accuracy    0.632           \n",
      "\n",
      "\n",
      "Model: /home/ajanco/spaCy_DH2019_workshop/unit3/new_model\n",
      "Training data: /home/ajanco/spaCy_DH2019_workshop/unit3/new_model/training.jsonl\n",
      "Evaluation data: /home/ajanco/spaCy_DH2019_workshop/unit3/new_model/evaluation.jsonl\n"
     ]
    }
   ],
   "source": [
    "!prodigy ner.batch-train historic_places new_model --output new_model --label PLACE --n-iter 120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Would our model improve with more data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 labels: PLACE\n",
      "\n",
      "Starting with model new_model\n",
      "Dropout: 0.2  Batch size: 32  Iterations: 10  Samples: 4\n",
      "\n",
      "%            RIGHT        WRONG        ACCURACY  \n",
      "25%          4            3            0.57         \u001b[38;5;77m+0.57\u001b[0m         \n",
      "50%          4            3            0.57         \u001b[38;5;197m+0.00\u001b[0m        \n",
      "75%          4            3            0.57         \u001b[38;5;197m+0.00\u001b[0m        \n",
      "100%         4            3            0.57         \u001b[38;5;197m+0.00\u001b[0m        \n"
     ]
    }
   ],
   "source": [
    "!prodigy ner.train-curve historic_places new_model --label PLACE --n-iter 10 --eval-split 0.2 --dropout 0.2  --n-samples 4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load and see the results of our new model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">ITEM because that the kings most deare Uncle, the king of \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Denmarke\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PLACE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Norway\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PLACE</span>\n",
       "</mark>\n",
       " &amp; \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Sweveland\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PLACE</span>\n",
       "</mark>\n",
       ", as the same our soveraigne Lord the king of his intimation hath understood, considering the manifold &amp; great losses, perils, hurts and damage which have late happened aswell to him and his, as to other foraines and strangers, and also friends and speciall subjects of our said soveraigne Lord the king of his \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Realme of England\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PLACE</span>\n",
       "</mark>\n",
       ", by ye going in, entring &amp; passage of such forain &amp; strange persons into his realme of Norwey &amp; other dominions, streits, territories, jurisdictions &amp; places subdued and subject to him, specially into his \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Iles of Fynmarke\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PLACE</span>\n",
       "</mark>\n",
       ", and elswhere, aswell in their persons as their things and goods</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"new_model\")\n",
    "doc = nlp(\n",
    "    \"ITEM because that the kings most deare Uncle, the king of Denmarke, Norway & Sweveland, as the same our soveraigne Lord the king of his intimation hath understood, considering the manifold & great losses, perils, hurts and damage which have late happened aswell to him and his, as to other foraines and strangers, and also friends and speciall subjects of our said soveraigne Lord the king of his Realme of England, by ye going in, entring & passage of such forain & strange persons into his realme of Norwey & other dominions, streits, territories, jurisdictions & places subdued and subject to him, specially into his Iles of Fynmarke, and elswhere, aswell in their persons as their things and goods\"\n",
    ")\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's not too bad.  What about a text that the model has never seen before? Let's try Çelebi Evliya's [Narrative of travels in Europe, Asia, and Africa](https://archive.org/details/narrativeoftrave01evli/page/n4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of the place ids were in the training data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The army marched from \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Konia\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PLACE</span>\n",
       "</mark>\n",
       " to \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Kaiseria\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PLACE</span>\n",
       "</mark>\n",
       " (\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Caesarea\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PLACE</span>\n",
       "</mark>\n",
       "), and thence to \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Sivas\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PLACE</span>\n",
       "</mark>\n",
       ", where the feast of the Korbân (sacrifice) was celebrated. Here Mustafâ \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Pâshâ\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PLACE</span>\n",
       "</mark>\n",
       ", the emperor's favourite, was promoted to the rank of second vezir, and called into the divân. The army then continued its march to Erzerum. Besides tiie guns provided by the commander-in-chief, there were forty large guns dragged by two thousand pairs of buftaloes. The army entered the castle of \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Kazmaghan\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PLACE</span>\n",
       "</mark>\n",
       ", and halted under the walls of Eriviin in the year 1044 (1634).  \n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"new_model\")\n",
    "doc = nlp(\n",
    "    \"\"\"The army marched from Konia to Kaiseria (Caesarea), and thence to Sivas, where the feast of the Korbân (sacrifice) was celebrated. Here Mustafâ Pâshâ, the emperor's favourite, was promoted to the rank of second vezir, and called into the divân. The army then continued its march to Erzerum. Besides tiie guns provided by the commander-in-chief, there were forty large guns dragged by two thousand pairs of buftaloes. The army entered the castle of Kazmaghan, and halted under the walls of Eriviin in the year 1044 (1634).  \n",
    "\"\"\"\n",
    ")\n",
    "counter = 0\n",
    "for ent in doc.ents:\n",
    "    if ent.text in places:\n",
    "        print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "        counter += 1\n",
    "\n",
    "print(f\"{counter} of the place ids were in the training data\")\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mustafâ Pâshâ is obviously a person, but the model has done as passable job. Let's use our model to automatically identify historical place names and produce a markedup TEI document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The army marched from <name type=\"place\">Konia</name> to <name type=\"place\">Kaiseria</name> (<name type=\"place\">Caesarea</name>), and thence to <name type=\"place\">Sivas</name>, where the feast of the Korbân (sacrifice) was celebrated. Here Mustafâ <name type=\"place\">Pâshâ</name>, the emperor \\'s favourite, was promoted to the rank of second vezir, and called into the divân. The army then continued its march to Erzerum. Besides tiie guns provided by the commander - in - chief, there were forty large guns dragged by two thousand pairs of buftaloes. The army entered the castle of <name type=\"place\">Kazmaghan</name>, and halted under the walls of Eriviin in the year 1044 (1634)'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"The army marched from Konia to Kaiseria (Caesarea), and thence to Sivas, where the feast of the Korbân (sacrifice) was celebrated. Here Mustafâ Pâshâ, the emperor's favourite, was promoted to the rank of second vezir, and called into the divân. The army then continued its march to Erzerum. Besides tiie guns provided by the commander-in-chief, there were forty large guns dragged by two thousand pairs of buftaloes. The army entered the castle of Kazmaghan, and halted under the walls of Eriviin in the year 1044 (1634).\"\"\"  \n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('new_model')\n",
    "doc = nlp(text)\n",
    "text_list = [i.text for i in doc]\n",
    "\n",
    "for token in doc:\n",
    "    if token.ent_type_ == 'PLACE': \n",
    "        text_list[token.i] = '<name type=\"place\">' + text_list[token.i] + '</name>'\n",
    "\n",
    "punct = ['.',\"'\",',',')',':',';']\n",
    "\n",
    "text=''\n",
    "for i, token in enumerate(text_list):\n",
    "    try:\n",
    "        if text_list[i+1] in punct:\n",
    "            text += token\n",
    "\n",
    "        else: \n",
    "            text += token + ' '\n",
    "        \n",
    "    except IndexError:\n",
    "        pass\n",
    "   \n",
    "    \n",
    "text.replace('\\n','').replace('( ','(')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save text as tei \n",
    "filename = 'my_tei.xml'\n",
    "language = 'en'\n",
    "\n",
    "tei_string = f\"\"\"\n",
    "<TEI.2>\n",
    "  <text lang=\"{language}\">\n",
    "    <body>\n",
    "        <p>\n",
    "            {text}\n",
    "        </p>\n",
    "    </body>\n",
    "  </text>\n",
    "</TEI.2>\n",
    "\"\"\"\n",
    "doc = etree.fromstring(tei_string)\n",
    "tree = etree.ElementTree(doc)\n",
    "tree.write(f'{filename}', pretty_print=True, xml_declaration=False,   encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TEI.2>\n",
      "  <text lang=\"en\">\n",
      "    <body>\n",
      "        <p>\n",
      "            The army marched from <name type=\"place\">Konia</name> to <name type=\"place\">Kaiseria</name> ( <name type=\"place\">Caesarea</name>), and thence to <name type=\"place\">Sivas</name>, where the feast of the Korbân ( sacrifice) was celebrated. Here Mustafâ <name type=\"place\">Pâshâ</name>, the emperor 's favourite, was promoted to the rank of second vezir, and called into the divân. The army then continued its march to Erzerum. Besides tiie guns provided by the commander - in - chief, there were forty large guns dragged by two thousand pairs of buftaloes. The army entered the castle of <name type=\"place\">Kazmaghan</name>, and halted under the walls of Eriviin in the year 1044 ( 1634)\n",
      "        </p>\n",
      "    </body>\n",
      "  </text>\n",
      "</TEI.2>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('my_tei.xml','r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. TEI to TEI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  ✨  Successfully added 'historic_places_xml' to database SQLite.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!prodigy dataset historic_places_xml \"A dataset for British historic places with TEI input\" --author Andy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.perseus.tufts.edu/hopper/xmlchunk?doc=Perseus%3Atext%3A1999.03.0070%3Anarrative%3D3\n",
      "b'<TEI.2><text lang=\"en\"><body><div1 type=\"narrative\" org=\"uniform\" sample=\"complete\"><head><foreign\n"
     ]
    }
   ],
   "source": [
    "#save xml file to disk\n",
    "with open('my_tei.txt','w') as f:\n",
    "    url = 'http://www.perseus.tufts.edu/hopper/xmlchunk?doc=' + refs[2]\n",
    "    print(url)\n",
    "    tei = urlopen(url).read()\n",
    "    tei = etree.XML(tei)\n",
    "    text = etree.tostring(tei)\n",
    "    f.write(str(text))\n",
    "\n",
    "with open('my_tei.txt','r') as fr:\n",
    "    print(fr.read()[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 labels: PLACE\n",
      "\n",
      "  ✨  Starting the web server at http://spacy.apjan.co:8080 ...\n",
      "  Open the app in your browser and start annotating!\n",
      "\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!prodigy ner.teach historic_places_xml en_core_web_sm my_tei.txt --label PLACE --patterns patterns.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prodigy as a manual annotation tool \n",
    "text > tei manual markup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"The army marched from Konia to Kaiseria (Caesarea), and thence to Sivas, where the feast of the Korbân (sacrifice) was celebrated. Here Mustafâ Pâshâ, the emperor's favourite, was promoted to the rank of second vezir, and called into the divân. The army then continued its march to Erzerum. Besides tiie guns provided by the commander-in-chief, there were forty large guns dragged by two thousand pairs of buftaloes. The army entered the castle of Kazmaghan, and halted under the walls of Eriviin in the year 1044 (1634).\"\"\"  \n",
    "with open('text2tei.txt','w') as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  ✨  Successfully added 'text2tei' to database SQLite.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!prodigy dataset text2tei \"A dataset for British historic places with text input\" --author Andy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 18 labels from model: LOC, FAC, PRODUCT, GPE, CARDINAL, QUANTITY, PERSON, EVENT, ORDINAL, MONEY, NORP, DATE, TIME, LAW, ORG, LANGUAGE, PERCENT, WORK_OF_ART\n",
      "\n",
      "  ✨  Starting the web server at http://spacy.apjan.co:8080 ...\n",
      "  Open the app in your browser and start annotating!\n",
      "\n",
      "Task queue depth is 1\n",
      "^C\n",
      "\n",
      "Saved 1 annotations to database SQLite\n",
      "Dataset: text2tei\n",
      "Session ID: 2019-06-30_14-10-50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!prodigy ner.manual text2tei en_core_web_sm text2tei.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  ✨  Exported 1 annotations for 'text2tei' from database SQLite\r\n",
      "  /home/ajanco/spaCy_DH2019_workshop/unit3/text2tei.jsonl\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!prodigy db-out text2tei ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'start': 22, 'end': 27, 'token_start': 4, 'token_end': 4, 'label': 'GPE'}, {'start': 31, 'end': 39, 'token_start': 6, 'token_end': 6, 'label': 'GPE'}, {'start': 66, 'end': 71, 'token_start': 14, 'token_end': 14, 'label': 'GPE'}, {'start': 83, 'end': 102, 'token_start': 18, 'token_end': 21, 'label': 'EVENT'}, {'start': 136, 'end': 149, 'token_start': 29, 'token_end': 30, 'label': 'PERSON'}, {'start': 282, 'end': 289, 'token_start': 59, 'token_end': 59, 'label': 'GPE'}, {'start': 448, 'end': 457, 'token_start': 92, 'token_end': 92, 'label': 'GPE'}, {'start': 489, 'end': 496, 'token_start': 100, 'token_end': 100, 'label': 'GPE'}, {'start': 509, 'end': 513, 'token_start': 104, 'token_end': 104, 'label': 'DATE'}]\n"
     ]
    }
   ],
   "source": [
    "with open('text2tei.jsonl','r') as f:\n",
    "    jsonl = json.loads(f.read())\n",
    "    print(jsonl['spans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The army marched from <GPE>Konia</GPE> to <GPE>Kaiseria</GPE> (Caesarea), and thence to <GPE>Sivas</GPE>, where the <EVENT>feast of the Korbân</EVENT> (sacrifice) was celebrated. Here <PERSON>Mustafâ Pâshâ</PERSON>, the emperor's favourite, was promoted to the rank of second vezir, and called into the divân. The army then continued its march to <GPE>Erzerum</GPE>. Besides tiie guns provided by the commander-in-chief, there were forty large guns dragged by two thousand pairs of buftaloes. The army entered the castle of <GPE>Kazmaghan</GPE>, and halted under the walls of <GPE>Eriviin</GPE> in the year <DATE>1044</DATE> (1634).\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "\n",
    "def jsonl_to_xml(jsonl):    \n",
    "    jsonl = json.loads(jsonl)\n",
    "    text = jsonl['text']\n",
    "    offset = 0\n",
    "    \n",
    "    for span in jsonl['spans']:\n",
    "\n",
    "        new_text = f\"<{span['label']}>\" + text[span[\"start\"] +offset : span[\"end\"] + offset] +  f\"</{span['label']}>\" \n",
    "        text = text[:span[\"start\"] + offset] + new_text + text[span[\"end\"] + offset:]\n",
    "        offset += len(new_text) - (span[\"end\"] - span[\"start\"])\n",
    "    \n",
    "    return text\n",
    "        \n",
    "\n",
    "with open('text2tei.jsonl','r') as f:\n",
    "    jsonl = f.read()\n",
    "    xml = jsonl_to_xml(jsonl)\n",
    "    print(xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TEI.2>\n",
      "  <text lang=\"en\">\n",
      "    <body>\n",
      "        <p>\n",
      "            The army marched from <GPE>Konia</GPE> to <GPE>Kaiseria</GPE> (Caesarea), and thence to <GPE>Sivas</GPE>, where the <EVENT>feast of the Korbân</EVENT> (sacrifice) was celebrated. Here <PERSON>Mustafâ Pâshâ</PERSON>, the emperor's favourite, was promoted to the rank of second vezir, and called into the divân. The army then continued its march to <GPE>Erzerum</GPE>. Besides tiie guns provided by the commander-in-chief, there were forty large guns dragged by two thousand pairs of buftaloes. The army entered the castle of <GPE>Kazmaghan</GPE>, and halted under the walls of <GPE>Eriviin</GPE> in the year <DATE>1044</DATE> (1634).\n",
      "        </p>\n",
      "    </body>\n",
      "  </text>\n",
      "</TEI.2>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# save text as tei \n",
    "filename = 'annotated_tei.xml'\n",
    "language = 'en'\n",
    "\n",
    "tei_string = f\"\"\"\n",
    "<TEI.2>\n",
    "  <text lang=\"{language}\">\n",
    "    <body>\n",
    "        <p>\n",
    "            {xml}\n",
    "        </p>\n",
    "    </body>\n",
    "  </text>\n",
    "</TEI.2>\n",
    "\"\"\"\n",
    "doc = etree.fromstring(tei_string)\n",
    "tree = etree.ElementTree(doc)\n",
    "tree.write(f'{filename}', pretty_print=True, xml_declaration=False,   encoding=\"utf-8\")\n",
    "\n",
    "with open(filename,'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tei > tei manual markup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "with open('output.html','r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tei\n",
    "# tei to standoff \n",
    "# tei to annotations\n",
    "# run ner.manual\n",
    "# export annotations prodigy db-out my_set /tmp\n",
    "# write annotations to TEI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#problem with training on standoff is that we lose ability to correct or remove markup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.perseus.tufts.edu/hopper/xmlchunk?doc=Perseus%3Atext%3A1999.03.0070%3Anarrative%3D3\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import standoffconverter # standoff_to_xml, tree_to_standoff\n",
    "\n",
    "url = 'http://www.perseus.tufts.edu/hopper/xmlchunk?doc=' + refs[2]\n",
    "print(url)\n",
    "tei = urlopen(url).read()\n",
    "tei = etree.XML(tei)\n",
    "\n",
    "def xml_to_jsonl(xml):\n",
    "    standoff = standoffconverter.tree_to_standoff(xml)\n",
    "    jsonl = {}\n",
    "    jsonl['text'] = standoff[0]\n",
    "    jsonl['spans'] = []\n",
    "    for tag in standoff[1]:\n",
    "        jsonl['spans'].append(tag)\n",
    "    \n",
    "    #change key names begin to start, type to label\n",
    "    for span in jsonl['spans']:\n",
    "        span['start'] = span.pop('begin')\n",
    "        span['label'] = span.pop('tag')\n",
    "        del span['attrib']\n",
    "        del span['depth']\n",
    "    return  json.dumps(jsonl)\n",
    "\n",
    "with open('apjanco.jsonl','w') as f:\n",
    "    \n",
    "    f.write(xml_to_jsonl(tei))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 18 labels from model: TIME, PERCENT, PERSON, FAC, NORP, ORDINAL, DATE, LAW, MONEY, LOC, LANGUAGE, GPE, CARDINAL, PRODUCT, QUANTITY, EVENT, ORG, WORK_OF_ART\n",
      "\n",
      "  ✨  Starting the web server at http://spacy.apjan.co:8080 ...\n",
      "  Open the app in your browser and start annotating!\n",
      "\n",
      "Task queue depth is 1\n",
      "Exception when serving /get_session_questions\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ajanco/spacy/lib/python3.7/site-packages/waitress/channel.py\", line 336, in service\n",
      "    task.service()\n",
      "  File \"/home/ajanco/spacy/lib/python3.7/site-packages/waitress/task.py\", line 175, in service\n",
      "    self.execute()\n",
      "  File \"/home/ajanco/spacy/lib/python3.7/site-packages/waitress/task.py\", line 452, in execute\n",
      "    app_iter = self.channel.server.application(env, start_response)\n",
      "  File \"/home/ajanco/spacy/lib/python3.7/site-packages/hug/api.py\", line 451, in api_auto_instantiate\n",
      "    return module.__hug_wsgi__(*args, **kwargs)\n",
      "  File \"/home/ajanco/spacy/lib/python3.7/site-packages/falcon/api.py\", line 244, in __call__\n",
      "    responder(req, resp, **params)\n",
      "  File \"/home/ajanco/spacy/lib/python3.7/site-packages/hug/interface.py\", line 789, in __call__\n",
      "    raise exception\n",
      "  File \"/home/ajanco/spacy/lib/python3.7/site-packages/hug/interface.py\", line 762, in __call__\n",
      "    self.render_content(self.call_function(input_parameters), context, request, response, **kwargs)\n",
      "  File \"/home/ajanco/spacy/lib/python3.7/site-packages/hug/interface.py\", line 698, in call_function\n",
      "    return self.interface(**parameters)\n",
      "  File \"/home/ajanco/spacy/lib/python3.7/site-packages/hug/interface.py\", line 100, in __call__\n",
      "    return __hug_internal_self._function(*args, **kwargs)\n",
      "  File \"/home/ajanco/spacy/lib/python3.7/site-packages/prodigy/_api/hug_app.py\", line 228, in get_session_questions\n",
      "    tasks = controller.get_questions(session_id=session_id)\n",
      "  File \"cython_src/prodigy/core.pyx\", line 130, in prodigy.core.Controller.get_questions\n",
      "  File \"cython_src/prodigy/components/feeds.pyx\", line 58, in prodigy.components.feeds.SharedFeed.get_questions\n",
      "  File \"cython_src/prodigy/components/feeds.pyx\", line 63, in prodigy.components.feeds.SharedFeed.get_next_batch\n",
      "  File \"cython_src/prodigy/components/feeds.pyx\", line 140, in prodigy.components.feeds.SessionFeed.get_session_stream\n",
      "  File \"/home/ajanco/spacy/lib/python3.7/site-packages/toolz/itertoolz.py\", line 368, in first\n",
      "    return next(iter(seq))\n",
      "  File \"cython_src/prodigy/components/preprocess.pyx\", line 130, in add_tokens\n",
      "  File \"cython_src/prodigy/components/preprocess.pyx\", line 160, in prodigy.components.preprocess._add_tokens\n",
      "ValueError: Mismatched tokenization. Can't resolve span to token index 78. This can happen if your data contains pre-set spans. Make sure that the spans match spaCy's tokenization or add a 'tokens' property to your task. \n",
      "\n",
      "{'end': 78, 'start': 78, 'label': 'p'}\n"
     ]
    }
   ],
   "source": [
    "!prodigy ner.manual historic_places en_core_web_sm apjanco.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy",
   "language": "python",
   "name": "spacy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
